{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 — PDF window\n",
        "\n",
        "Loads the PDF and auto-selects the useful page window (skips front matter and reference blocks).\n",
        "Uses simple heading/look-ahead rules to pause at “References” and resume if a new chapter starts.\n",
        "Emits the selected page texts plus their original page indices for downstream steps."
      ],
      "metadata": {
        "id": "vxF3-JhxpRaV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FYvBd9BQtZ7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919c7e8f-0355-4a2f-e18d-7470123f4e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 257 pages from: /content/PhDThesis__Masurel2015.pdf\n",
            "\n",
            "=== SMART WINDOW SUMMARY ===\n",
            "Total pages: 257\n",
            "Selected pages: 234\n",
            "From page 19 to 252\n",
            "\n",
            "--- Start page preview ---\n",
            "    1    Chapter I. Introduction     1. Preamble and knowledge gaps    Paleoproterozoic (i.e. Biri mian) volcano-plutonic belts and sedimentary basins  of West Africa not only  provide a complete record of crustal growth but also host a  number of world-class gold deposits (Abouc hami et al., 1990; Boher et al., 1992). To  date, a large number of studies have focused on the Baoulé-Mossi domain, which covers  portions of Burkina Faso, Côte d’Ivoire, Ghana, Guinea and Mali (Fig. 1). Gold  deposits\n",
            "\n",
            "--- End page preview ---\n",
            "    234    3. Future work    Despite the work undertaken by the candi date, a number of questions remain  unanswered, some of which are directly relevant to exploration targeting:     3.1. Source of fluids and metals    Recent research suggests that the divers ity in mineralisation styles and ore  paragenesis expressed in the KKI result from a dynamic hydrothermal system that  sourced fluids and metals from both metamo rphic and magmatic reservoirs (Lawrence  et al., 2013a, b; Treloar et al., 20\n"
          ]
        }
      ],
      "source": [
        "# ===== Step 1) PDF Loader & Smart Windowing with Pause/Resume (Google Colab) =====\n",
        "!pip -q install pypdf\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "from pypdf import PdfReader\n",
        "\n",
        "PDF_PATH = \"/content/PhDThesis__Masurel2015.pdf\"\n",
        "\n",
        "assert PDF_PATH is not None and Path(PDF_PATH).exists(), \"PDF_PATH not set or file not found.\"\n",
        "\n",
        "# === Config ===\n",
        "MIN_SKIP_PAGES = 17\n",
        "MAX_SKIP_PAGES_FALLBACK = 19\n",
        "TAIL_EXCLUDE_PAGES = 5\n",
        "LOOKAHEAD_PAGES = 6  # how far to look ahead after \"References\"\n",
        "\n",
        "INTRO_PATTERNS = [\n",
        "    r'^\\s*(chapter\\s+\\w+\\.?\\s+)?introduction\\b',\n",
        "    r'^\\s*introduction\\b',\n",
        "]\n",
        "STOP_HEADINGS = [\n",
        "    r'^\\s*references\\b',\n",
        "    r'^\\s*bibliograph(y|ies)\\b',\n",
        "    r'^\\s*acknowledg(e)?ments\\b',\n",
        "]\n",
        "SECTION_HEADINGS = [\n",
        "    r'^\\s*chapter\\s+[ivxlcdm]+\\b',\n",
        "    r'^\\s*chapter\\s+\\d+\\b',\n",
        "    r'^\\s*\\d+\\.\\s+[A-Z]',\n",
        "]\n",
        "\n",
        "# === Helpers ===\n",
        "def read_pdf_pages_text(pdf_path: str):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    return [page.extract_text() or \"\" for page in reader.pages]\n",
        "\n",
        "def match_any(text, patterns):\n",
        "    for pat in patterns:\n",
        "        if re.search(pat, text, flags=re.IGNORECASE | re.MULTILINE):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def first_intro_page(pages_text):\n",
        "    for i in range(MIN_SKIP_PAGES, len(pages_text)):\n",
        "        if match_any(pages_text[i][:2000], INTRO_PATTERNS):\n",
        "            return i\n",
        "    return MAX_SKIP_PAGES_FALLBACK\n",
        "\n",
        "def smart_extract_window(pages_text):\n",
        "    N = len(pages_text)\n",
        "    start_idx = min(first_intro_page(pages_text), N-1)\n",
        "    selected, skipping = [], False\n",
        "\n",
        "    i = start_idx\n",
        "    while i < N - TAIL_EXCLUDE_PAGES:\n",
        "        head = (pages_text[i] or \"\")[:1500]\n",
        "\n",
        "        if match_any(head, STOP_HEADINGS):\n",
        "            # pause extraction at refs\n",
        "            lookahead_text = \" \".join(pages_text[i+1:i+LOOKAHEAD_PAGES+1])\n",
        "            if match_any(lookahead_text, SECTION_HEADINGS):\n",
        "                # skip this refs block, then resume after lookahead\n",
        "                print(f\"Skipped References block at page {i+1}, resuming later…\")\n",
        "                i += LOOKAHEAD_PAGES\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"Final stop at References block on page {i+1}\")\n",
        "                break\n",
        "\n",
        "        selected.append((i, pages_text[i]))\n",
        "        i += 1\n",
        "\n",
        "    return selected, start_idx\n",
        "\n",
        "# === Run ===\n",
        "pages_text = read_pdf_pages_text(PDF_PATH)\n",
        "N = len(pages_text)\n",
        "print(f\"Loaded {N} pages from: {PDF_PATH}\")\n",
        "\n",
        "selected_pairs, start_idx = smart_extract_window(pages_text)\n",
        "selected_pages_text = [t for _, t in selected_pairs]\n",
        "selected_indices = [i for i, _ in selected_pairs]\n",
        "\n",
        "print(\"\\n=== SMART WINDOW SUMMARY ===\")\n",
        "print(f\"Total pages: {N}\")\n",
        "print(f\"Selected pages: {len(selected_pages_text)}\")\n",
        "print(f\"From page {selected_indices[0]+1} to {selected_indices[-1]+1}\")\n",
        "\n",
        "# Peek at first and last selected page\n",
        "print(\"\\n--- Start page preview ---\")\n",
        "print(selected_pages_text[0][:500].replace(\"\\n\", \" \"))\n",
        "print(\"\\n--- End page preview ---\")\n",
        "print(selected_pages_text[-1][:500].replace(\"\\n\", \" \"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 — Block extraction\n",
        "\n",
        "Splits each selected page into fine-grained blocks (sentences, table rows, captions) with a heuristic block_type.\n",
        "Assigns stable page_num and block_id for traceable provenance.\n",
        "Emits df_blocks for later filtering."
      ],
      "metadata": {
        "id": "ozFJ2FiYpT7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 2) Block Extraction: sentences, tables, captions =====\n",
        "!pip -q install nltk\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True) # Add this line\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "def detect_block_type(text):\n",
        "    \"\"\"Heuristic block classifier\"\"\"\n",
        "    # Table-like if many numbers or tab spacing\n",
        "    if re.search(r\"\\d\", text) and (text.count(\" \") > 10 or \"\\t\" in text):\n",
        "        return \"table_row\"\n",
        "    # Caption if starts with Figure/Table\n",
        "    if re.match(r\"^\\s*(figure|fig\\.|table)\\s+\\d+\", text, re.I):\n",
        "        return \"caption\"\n",
        "    return \"sentence\"\n",
        "\n",
        "def extract_blocks(pages_text, page_indices):\n",
        "    blocks = []\n",
        "    for local_idx, page_text in enumerate(pages_text):\n",
        "        page_num = page_indices[local_idx] + 1  # human page number\n",
        "        # Split page into paragraphs/lines\n",
        "        chunks = [c.strip() for c in page_text.split(\"\\n\") if c.strip()]\n",
        "        block_id = 0\n",
        "        for chunk in chunks:\n",
        "            block_type = detect_block_type(chunk)\n",
        "            # If sentence mode: split further\n",
        "            if block_type == \"sentence\":\n",
        "                sentences = sent_tokenize(chunk)\n",
        "                for sent in sentences:\n",
        "                    blocks.append({\n",
        "                        \"page_num\": page_num,\n",
        "                        \"block_id\": f\"{page_num}-{block_id}\",\n",
        "                        \"block_type\": \"sentence\",\n",
        "                        \"text\": sent\n",
        "                    })\n",
        "                    block_id += 1\n",
        "            else:\n",
        "                blocks.append({\n",
        "                    \"page_num\": page_num,\n",
        "                    \"block_id\": f\"{page_num}-{block_id}\",\n",
        "                    \"block_type\": block_type,\n",
        "                    \"text\": chunk\n",
        "                })\n",
        "                block_id += 1\n",
        "    return pd.DataFrame(blocks)\n",
        "\n",
        "# Run block extraction\n",
        "df_blocks = extract_blocks(selected_pages_text, selected_indices)\n",
        "\n",
        "print(f\"Extracted {len(df_blocks)} blocks\")\n",
        "display(df_blocks.head(10)) # Use display for better output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "KgIFRioFNYDS",
        "outputId": "7ba5bbc4-d8ae-40dd-ec57-76a9f0ab5ac8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 5825 blocks\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   page_num block_id block_type  \\\n",
              "0        19     19-0   sentence   \n",
              "1        19     19-1   sentence   \n",
              "2        19     19-2   sentence   \n",
              "3        19     19-3   sentence   \n",
              "4        19     19-4   sentence   \n",
              "5        19     19-5   sentence   \n",
              "6        19     19-6   sentence   \n",
              "7        19     19-7   sentence   \n",
              "8        19     19-8  table_row   \n",
              "9        19     19-9   sentence   \n",
              "\n",
              "                                                text  \n",
              "0                                                  1  \n",
              "1                                         Chapter I.  \n",
              "2                                       Introduction  \n",
              "3                                                 1.  \n",
              "4                        Preamble and knowledge gaps  \n",
              "5                             Paleoproterozoic (i.e.  \n",
              "6  Biri mian) volcano-plutonic belts and sediment...  \n",
              "7  of West Africa not only  provide a complete re...  \n",
              "8  number of world-class gold deposits (Abouc ham...  \n",
              "9  date, a large number of studies have focused o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-663c8e81-a370-4845-aa0e-6ab641e83fe4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_num</th>\n",
              "      <th>block_id</th>\n",
              "      <th>block_type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19-0</td>\n",
              "      <td>sentence</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>19-1</td>\n",
              "      <td>sentence</td>\n",
              "      <td>Chapter I.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>19-2</td>\n",
              "      <td>sentence</td>\n",
              "      <td>Introduction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>19-3</td>\n",
              "      <td>sentence</td>\n",
              "      <td>1.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>19-4</td>\n",
              "      <td>sentence</td>\n",
              "      <td>Preamble and knowledge gaps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>19</td>\n",
              "      <td>19-5</td>\n",
              "      <td>sentence</td>\n",
              "      <td>Paleoproterozoic (i.e.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19</td>\n",
              "      <td>19-6</td>\n",
              "      <td>sentence</td>\n",
              "      <td>Biri mian) volcano-plutonic belts and sediment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>19</td>\n",
              "      <td>19-7</td>\n",
              "      <td>sentence</td>\n",
              "      <td>of West Africa not only  provide a complete re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19</td>\n",
              "      <td>19-8</td>\n",
              "      <td>table_row</td>\n",
              "      <td>number of world-class gold deposits (Abouc ham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>19</td>\n",
              "      <td>19-9</td>\n",
              "      <td>sentence</td>\n",
              "      <td>date, a large number of studies have focused o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-663c8e81-a370-4845-aa0e-6ab641e83fe4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-663c8e81-a370-4845-aa0e-6ab641e83fe4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-663c8e81-a370-4845-aa0e-6ab641e83fe4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5829673b-2c59-4acb-bfa1-456c230d738c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5829673b-2c59-4acb-bfa1-456c230d738c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5829673b-2c59-4acb-bfa1-456c230d738c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_blocks\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"page_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 19,\n        \"max\": 19,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"block_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"19-8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"block_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"table_row\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"number of world-class gold deposits (Abouc hami et al., 1990; Boher et al., 1992). To\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 — Candidate finder\n",
        "\n",
        "Loads a ready-to-use DICT (core geo terms, units, and aliases/normalisers).\n",
        "Scans each block for domain keywords and quantitative patterns (number+unit, ranges, ±error, oxide %); guards against dates/citations.\n",
        "Emits a shortlisted DataFrame with provenance + parsed numbers, and saves it to /content/candidate_blocks_step3.csv."
      ],
      "metadata": {
        "id": "2HrU6YYIpY5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 3) Dictionary & Regex Pre-Filter (tightened) =====\n",
        "!pip -q install pandas rapidfuzz\n",
        "\n",
        "import re, json\n",
        "from collections import Counter\n",
        "from rapidfuzz import process, fuzz\n",
        "import pandas as pd\n",
        "\n",
        "# ---- A) Dictionary (extend anytime) ----\n",
        "DICT = {\n",
        "    \"rock_type\": [\n",
        "        \"limestone\",\"dolomite\",\"dolostone\",\"wacke\",\"arenite\",\"siltstone\",\"argillite\",\n",
        "        \"mudstone\",\"shale\",\"sandstone\",\"conglomerate\",\"breccia\",\"granite\",\"monzogranite\",\n",
        "        \"granodiorite\",\"diorite\",\"tonalite\",\"gabbro\",\"basalt\",\"andesite\",\"rhyolite\",\n",
        "        \"komatiite\",\"trachyte\",\"phonolite\",\"gneiss\",\"schist\",\"quartzite\"\n",
        "    ],\n",
        "    \"minerals\": [\n",
        "        \"pyrite\",\"arsenopyrite\",\"chalcopyrite\",\"pyrrhotite\",\"sphalerite\",\"galena\",\n",
        "        \"magnetite\",\"hematite\",\"native gold\",\"electrum\",\"muscovite\",\"biotite\",\n",
        "        \"chlorite\",\"sericite\",\"albite\",\"epidote\",\"carbonate\",\"quartz\",\"feldspar\"\n",
        "    ],\n",
        "    \"mineralisation\": [\n",
        "        \"sulfide\",\"sulphide\",\"stockwork\",\"vein\",\"disseminated\",\"massive\",\"breccia\",\n",
        "        \"replacement\",\"porphyry\",\"orogenic\"\n",
        "    ],\n",
        "    \"tectonism_event\": [\n",
        "        \"D1\",\"D2\",\"D3\",\"D4\",\"compressional\",\"extensional\",\"transcurrent\",\n",
        "        \"sinistral\",\"dextral\",\"thrust\",\"fold\",\"shear zone\",\"shear\"\n",
        "    ],\n",
        "    \"structures\": [\n",
        "        \"foliation\",\"lineation\",\"cleavage\",\"vein\",\"veinlet\",\"breccia\",\"schistosity\",\n",
        "        \"plunge\",\"strike\",\"dip\",\"bedding\",\"lamination\",\"fault\"\n",
        "    ],\n",
        "    \"methods\": [\n",
        "        \"ICP-MS\",\"LA-ICP-MS\",\"EPMA\",\"SEM\",\"XRD\",\"XRF\",\"AAS\",\"fire assay\",\n",
        "        \"TIMS\",\"ID-TIMS\",\"MC-ICP-MS\",\"SIMS\",\"LAICPMS\",\"microprobe\"\n",
        "    ],\n",
        "    \"geochronology_terms\": [\n",
        "        \"zircon\",\"monazite\",\"baddeleyite\",\"concordia\",\"intercept\",\"weighted mean\",\n",
        "        \"MSWD\",\"discordant\",\"206Pb/238U\",\"207Pb/206Pb\",\"U–Pb\",\"U-Pb\",\"age\",\"dated\"\n",
        "    ],\n",
        "    \"assay_elements\": [\n",
        "        \"Au\",\"Ag\",\"As\",\"Sb\",\"Cu\",\"Pb\",\"Zn\",\"Ni\",\"Co\",\"Fe\",\"S\",\n",
        "        \"SiO2\",\"Al2O3\",\"MgO\",\"CaO\",\"K2O\",\"Na2O\",\"TiO2\",\"P2O5\",\"LOI\",\"Cr2O3\",\"MnO\"\n",
        "    ],\n",
        "    \"units\": [\"ppm\",\"ppb\",\"wt%\",\"%\",\"g/t\",\"mg/kg\",\"µg/g\",\"ug/g\",\"Ma\",\"Ga\",\"°C\",\"deg C\"],\n",
        "    \"stopwords_geo\": [\"references\",\"bibliography\",\"acknowledgements\",\"appendix\"]\n",
        "}\n",
        "\n",
        "UNIT_NORMALISE = {\"gpt\": \"g/t\", \"percent\": \"%\", \"ug/g\": \"µg/g\", \"deg c\": \"°C\"}\n",
        "ALIAS_MAP = {\n",
        "    \"gold\":\"Au\",\"arsenic\":\"As\",\"antimony\":\"Sb\",\"copper\":\"Cu\",\"lead\":\"Pb\",\"zinc\":\"Zn\",\n",
        "    \"nickel\":\"Ni\",\"cobalt\":\"Co\",\"sulfur\":\"S\",\"sulphur\":\"S\"\n",
        "}\n",
        "\n",
        "def normalise_unit(u: str|None) -> str|None:\n",
        "    if not u: return None\n",
        "    u = u.strip().lower()\n",
        "    return UNIT_NORMALISE.get(u, u).replace(\"ug/g\",\"µg/g\")\n",
        "\n",
        "def alias_text(text: str) -> str:\n",
        "    low = text.lower()\n",
        "    for k, v in ALIAS_MAP.items():\n",
        "        low = re.sub(rf\"\\b{k}\\b\", v.lower(), low)\n",
        "    return low\n",
        "\n",
        "# ---- B) Numeric/Unit regex ----\n",
        "NUM = r\"\\d+(?:[\\.,]\\d+)?\"\n",
        "RANGE_SEP = r\"(?:–|-|to)\"\n",
        "PATTERNS = {\n",
        "    \"num_unit\": re.compile(rf\"(?P<val>{NUM})\\s*(?P<unit>ppm|ppb|wt%|%|g\\/t|mg\\/kg|µg\\/g|ug\\/g|Ma|Ga|°C)\\b\", re.I),\n",
        "    \"range\": re.compile(rf\"(?P<v1>{NUM})\\s*{RANGE_SEP}\\s*(?P<v2>{NUM})\\s*(?P<unit>ppm|ppb|%|g\\/t|Ma|Ga)?\\b\", re.I),\n",
        "    \"between_age\": re.compile(rf\"\\bbetween\\s+(?P<v1>{NUM})\\s*(?:–|-|to|and)\\s*(?P<v2>{NUM})\\s*(?P<unit>Ma|Ga)\\b\", re.I),\n",
        "    \"plusminus\": re.compile(rf\"(?P<mean>{NUM})\\s*(?:±|\\+\\/-)\\s*(?P<err>{NUM})\\s*(?P<unit>Ma|g\\/t|ppm|%|°C)?\\b\", re.I),\n",
        "    \"oxide_pct\": re.compile(rf\"(?P<oxide>[A-Z][a-z]?(?:\\d)?O\\d?)\\s*(?P<val>{NUM})\\s*%\", re.I),\n",
        "}\n",
        "\n",
        "# ---- C) Noise guards & context checks ----\n",
        "MONTHS = r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|june|july|august|september|october|november|december)\"\n",
        "CITATION_CUES = r\"\\b(journal|geological society|special publications|bulletin|v\\.|vol\\.|issue|no\\.|pp?\\.|doi:|issn|isbn|proceedings|symposium|conference|abstracts|et al\\.)\\b\"\n",
        "\n",
        "RANGE_CONTEXT_OK = [\n",
        "    \"ma\",\"ga\",\"age\",\"dated\",\"u–pb\",\"u-pb\",\"zircon\",\"monazite\",\"concordia\",\"intercept\",\n",
        "    \"ppm\",\"ppb\",\"g/t\",\"wt%\",\"%\",\"oxide\",\"sio2\",\"feo\",\"tio2\",\"mgo\",\"cao\",\"k2o\",\"na2o\",\"p2o5\",\n",
        "    \"mg#\",\"mswd\"\n",
        "]\n",
        "\n",
        "def has_range_context(text: str) -> bool:\n",
        "    low = text.lower()\n",
        "    return any(tok in low for tok in RANGE_CONTEXT_OK)\n",
        "\n",
        "def looks_like_date_or_citation(text: str) -> bool:\n",
        "    low = text.lower()\n",
        "    if re.search(MONTHS, low) and re.search(r\"\\b\\d{1,2}\\s*(?:–|-|to)\\s*\\d{1,2}\\b\", low):\n",
        "        return True\n",
        "    if re.search(CITATION_CUES, low) and re.search(r\"\\b\\d{2,6}\\s*(?:–|-|to)\\s*\\d{2,6}\\b\", low):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def age_signal_present(text: str) -> bool:\n",
        "    low = text.lower()\n",
        "    return any(tok in low for tok in [\"u–pb\",\"u-pb\",\"concordia\",\"mswd\",\"age\",\"dated\"])\n",
        "\n",
        "# ---- D) Candidate finder over df_blocks ----\n",
        "def find_candidates_from_blocks(df_blocks, min_keywords=1, require_numeric=True, fuzzy_cutoff=95):\n",
        "    recs = []\n",
        "    for _, row in df_blocks.iterrows():\n",
        "        raw_text = str(row[\"text\"]).strip()\n",
        "        if not raw_text:\n",
        "            continue\n",
        "\n",
        "        low = alias_text(raw_text)\n",
        "\n",
        "        # Stronger citation/date guard: allow only if explicit unit/± OR clear age signal\n",
        "        if looks_like_date_or_citation(raw_text):\n",
        "            if not (PATTERNS[\"num_unit\"].search(raw_text) or PATTERNS[\"plusminus\"].search(raw_text) or age_signal_present(raw_text)):\n",
        "                continue\n",
        "\n",
        "        # Keyword categories\n",
        "        keyword_hits = set()\n",
        "        for cat, terms in DICT.items():\n",
        "            if cat in (\"units\",\"stopwords_geo\"):\n",
        "                continue\n",
        "            if any(t.lower() in low for t in terms):\n",
        "                keyword_hits.add(cat); continue\n",
        "            best = process.extractOne(low, terms, scorer=fuzz.partial_ratio, score_cutoff=fuzzy_cutoff)\n",
        "            if best: keyword_hits.add(cat)\n",
        "\n",
        "        if len(keyword_hits) < min_keywords:\n",
        "            continue\n",
        "\n",
        "        # Quantitative patterns\n",
        "        m_numunit   = list(PATTERNS[\"num_unit\"].finditer(raw_text))\n",
        "        m_pm        = list(PATTERNS[\"plusminus\"].finditer(raw_text))\n",
        "        m_oxide     = list(PATTERNS[\"oxide_pct\"].finditer(raw_text))\n",
        "        m_range     = list(PATTERNS[\"range\"].finditer(raw_text))\n",
        "        m_between   = list(PATTERNS[\"between_age\"].finditer(raw_text))\n",
        "\n",
        "        explicit_ok = bool(m_numunit or m_pm or m_oxide)\n",
        "        valid_numeric = explicit_ok\n",
        "\n",
        "        # Allow ranges only with context; require stronger geo signal if still unit-less\n",
        "        if not explicit_ok:\n",
        "            if (m_range or m_between) and has_range_context(raw_text):\n",
        "                valid_numeric = len(keyword_hits) >= 2\n",
        "            else:\n",
        "                valid_numeric = False\n",
        "\n",
        "        # Co-occurrence rule for Ma/Ga without ± :\n",
        "        if explicit_ok and not m_pm:\n",
        "            # if ONLY Ma/Ga units found (no ppm/%/g/t/°C), demand geochron signal or ≥2 categories\n",
        "            only_age_units = all((m.group(\"unit\") or \"\").lower() in [\"ma\",\"ga\"] for m in m_numunit) if m_numunit else False\n",
        "            if only_age_units and not ((\"geochronology_terms\" in keyword_hits) or (len(keyword_hits) >= 2)):\n",
        "                valid_numeric = False\n",
        "\n",
        "        if require_numeric and not valid_numeric:\n",
        "            continue\n",
        "\n",
        "        # Parse numbers\n",
        "        numbers = []\n",
        "        for m in m_numunit:\n",
        "            numbers.append({\n",
        "                \"type\":\"num_unit\",\n",
        "                \"value\": float(m.group(\"val\").replace(\",\", \".\")),\n",
        "                \"unit\":  normalise_unit(m.group(\"unit\"))\n",
        "            })\n",
        "        for m in m_pm:\n",
        "            numbers.append({\n",
        "                \"type\":\"plusminus\",\n",
        "                \"mean\":  float(m.group(\"mean\").replace(\",\", \".\")),\n",
        "                \"error\": float(m.group(\"err\").replace(\",\", \".\")),\n",
        "                \"unit\":  normalise_unit(m.group(\"unit\"))\n",
        "            })\n",
        "        for m in m_oxide:\n",
        "            numbers.append({\n",
        "                \"type\":\"oxide_pct\",\n",
        "                \"oxide\": m.group(\"oxide\"),\n",
        "                \"value\": float(m.group(\"val\").replace(\",\", \".\")),\n",
        "                \"unit\":  \"%\"\n",
        "            })\n",
        "        # Age ranges\n",
        "        if m_between:\n",
        "            for m in m_between:\n",
        "                numbers.append({\n",
        "                    \"type\":\"range\",\n",
        "                    \"value_min\": float(m.group(\"v1\").replace(\",\", \".\")),\n",
        "                    \"value_max\": float(m.group(\"v2\").replace(\",\", \".\")),\n",
        "                    \"unit\":      normalise_unit(m.group(\"unit\"))\n",
        "                })\n",
        "        elif m_range and has_range_context(raw_text) and len(keyword_hits) >= 2:\n",
        "            for m in m_range:\n",
        "                numbers.append({\n",
        "                    \"type\":\"range\",\n",
        "                    \"value_min\": float(m.group(\"v1\").replace(\",\", \".\")),\n",
        "                    \"value_max\": float(m.group(\"v2\").replace(\",\", \".\")),\n",
        "                    \"unit\":      normalise_unit(m.group(\"unit\")) if m.group(\"unit\") else None\n",
        "                })\n",
        "\n",
        "        if not numbers:\n",
        "            continue\n",
        "\n",
        "        recs.append({\n",
        "            \"page_num\": row[\"page_num\"],\n",
        "            \"block_id\": row[\"block_id\"],\n",
        "            \"block_type\": row[\"block_type\"],\n",
        "            \"text\": raw_text,\n",
        "            \"keyword_categories\": sorted(list(keyword_hits)),\n",
        "            \"numbers_json\": json.dumps(numbers, ensure_ascii=False),\n",
        "            \"has_numbers\": True\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame.from_records(recs)\n",
        "\n",
        "# ---- E) Run and save ----\n",
        "df_cands = find_candidates_from_blocks(df_blocks, min_keywords=1, require_numeric=True)\n",
        "\n",
        "df_cands = df_cands.sort_values([\"page_num\",\"block_id\"]).reset_index(drop=True)\n",
        "print(f\"Candidate blocks found: {len(df_cands)}\")\n",
        "\n",
        "display_cols = [\"page_num\",\"block_id\",\"block_type\",\"keyword_categories\",\"text\",\"numbers_json\"]\n",
        "print(df_cands[display_cols].head(12).to_string(index=False)[:2500])\n",
        "\n",
        "OUT_PATH = \"/content/candidate_blocks_step3.csv\"\n",
        "df_cands.to_csv(OUT_PATH, index=False)\n",
        "print(f\"\\nSaved candidates → {OUT_PATH}\")\n",
        "\n",
        "# Quick category stats\n",
        "cat_counts = Counter()\n",
        "for cats in df_cands[\"keyword_categories\"]:\n",
        "    for c in cats:\n",
        "        cat_counts[c] += 1\n",
        "print(\"\\nTop categories (rough):\")\n",
        "for c, n in cat_counts.most_common(12):\n",
        "    print(f\"  {c:22s} {n}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBDcEIsoNepL",
        "outputId": "5fb15082-0d40-4be8-d352-c64fb5eb1375"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate blocks found: 174\n",
            " page_num block_id block_type                               keyword_categories                                                                                    text                                                                                                                                                                                                                               numbers_json\n",
            "       19    19-18  table_row                                 [assay_elements]  2158 Ma gold at Wassa, Parra-Avila, in press; 2105 ± 2 Ma gold at Ashanti, Oberthür et                                                                 [{\"type\": \"num_unit\", \"value\": 2158.0, \"unit\": \"ma\"}, {\"type\": \"num_unit\", \"value\": 2.0, \"unit\": \"ma\"}, {\"type\": \"plusminus\", \"mean\": 2105.0, \"error\": 2.0, \"unit\": \"ma\"}]\n",
            "       19    19-19  table_row                                 [assay_elements]     al., 1998; 2063 ± 9 Ma gold at Damang, Pigois et al., 2003). Nevertheless, the vast                                                                                                                      [{\"type\": \"num_unit\", \"value\": 9.0, \"unit\": \"ma\"}, {\"type\": \"plusminus\", \"mean\": 2063.0, \"error\": 9.0, \"unit\": \"ma\"}]\n",
            "       19    19-23  table_row            [assay_elements, geochronology_terms]           Eburnean orogeny dated between 2115 and 2060 Ma (e.g., Feybesse et al., 2006;                                                                                                           [{\"type\": \"num_unit\", \"value\": 2060.0, \"unit\": \"ma\"}, {\"type\": \"range\", \"value_min\": 2115.0, \"value_max\": 2060.0, \"unit\": \"ma\"}]\n",
            "       42    42-18  table_row [assay_elements, geochronology_terms, rock_type]      dated between 2160 ± 16 Ma (Boher et al., 199 2; Sm-Nd on whole rock andesite) and                                                                                                                    [{\"type\": \"num_unit\", \"value\": 16.0, \"unit\": \"ma\"}, {\"type\": \"plusminus\", \"mean\": 2160.0, \"error\": 16.0, \"unit\": \"ma\"}]\n",
            "       42    42-19  table_row                      [assay_elements, rock_type]       2197 ± 13 Ma (Dia, 1988; Sm-Nd on whole rock  basalt). The Mako crustal rocks are                                                                                                                    [{\"type\": \"num_unit\", \"value\": 13.0, \"unit\": \"ma\"}, {\"type\": \"plusminus\", \"mean\": 2197.0, \"error\": 13.0, \"unit\": \"ma\"}]\n",
            "       42    42-21  table_row [assay_elements, geochronology_terms, rock_type]       Mam\n",
            "\n",
            "Saved candidates → /content/candidate_blocks_step3.csv\n",
            "\n",
            "Top categories (rough):\n",
            "  assay_elements         173\n",
            "  geochronology_terms    94\n",
            "  minerals               30\n",
            "  rock_type              21\n",
            "  mineralisation         10\n",
            "  methods                6\n",
            "  tectonism_event        4\n",
            "  structures             3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 — Offline facts (with tectonism + tags)\n",
        "\n",
        "Converts each numbers_json hit into one atomic fact with category/attribute/values/units/method.\n",
        "Auto-classifies: Ma/Ga or age cues → geochronology; age + D1–D4/shear/thrust → tectonism_event (entity = D-stage); element symbols → assay; else geochemistry.\n",
        "Adds context snippet + confidence and writes /content/extracted_step4_offline.csv."
      ],
      "metadata": {
        "id": "M4G2Cn14pdig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 4) Offline Structured Extraction (+ tectonism + dict tags) =====\n",
        "import json, re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Inputs ---\n",
        "CANDS_PATH = \"/content/candidate_blocks_step3.csv\"        # from Step 3\n",
        "OUT_JSONL  = \"/content/extracted_step4_offline.jsonl\"\n",
        "OUT_CSV    = \"/content/extracted_step4_offline.csv\"\n",
        "OUT_PARQ   = \"/content/extracted_step4_offline.parquet\"\n",
        "\n",
        "assert Path(CANDS_PATH).exists(), f\"Missing {CANDS_PATH}\"\n",
        "df_cands = pd.read_csv(CANDS_PATH)\n",
        "\n",
        "# --- Minimal fallbacks (use your Step-3 dicts if already defined) ---\n",
        "try: DICT\n",
        "except NameError:\n",
        "    DICT = {\n",
        "        \"assay_elements\":[\"Au\",\"Ag\",\"As\",\"Sb\",\"Cu\",\"Pb\",\"Zn\",\"Ni\",\"Co\",\"Fe\",\"S\",\n",
        "                          \"SiO2\",\"Al2O3\",\"MgO\",\"CaO\",\"K2O\",\"Na2O\",\"TiO2\",\"P2O5\",\"LOI\",\"Cr2O3\",\"MnO\"],\n",
        "        \"methods\":[\"ICP-MS\",\"LA-ICP-MS\",\"EPMA\",\"SEM\",\"XRD\",\"XRF\",\"AAS\",\"fire assay\",\n",
        "                   \"TIMS\",\"ID-TIMS\",\"MC-ICP-MS\",\"SIMS\",\"LAICPMS\",\"microprobe\"],\n",
        "        \"geochronology_terms\":[\"zircon\",\"monazite\",\"baddeleyite\",\"concordia\",\"mswd\",\"age\",\"dated\",\"U–Pb\",\"U-Pb\"],\n",
        "        \"rock_type\":[\"limestone\",\"dolomite\",\"wacke\",\"sandstone\",\"breccia\",\"granite\",\"tonalite\",\"gabbro\",\"basalt\",\"andesite\",\"rhyolite\",\"gneiss\",\"schist\",\"quartzite\"],\n",
        "        \"minerals\":[\"pyrite\",\"arsenopyrite\",\"chalcopyrite\",\"pyrrhotite\",\"sphalerite\",\"galena\",\"magnetite\",\"hematite\",\"muscovite\",\"biotite\",\"chlorite\",\"sericite\",\"albite\",\"epidote\",\"quartz\",\"feldspar\",\"carbonate\"],\n",
        "        \"mineralisation\":[\"sulfide\",\"sulphide\",\"stockwork\",\"vein\",\"disseminated\",\"massive\",\"breccia\",\"replacement\",\"porphyry\",\"orogenic\"],\n",
        "        \"structures\":[\"foliation\",\"lineation\",\"cleavage\",\"vein\",\"breccia\",\"schistosity\",\"plunge\",\"strike\",\"dip\",\"bedding\",\"lamination\",\"fault\"],\n",
        "        \"tectonism_event\":[\"D1\",\"D2\",\"D3\",\"D4\",\"compressional\",\"extensional\",\"transcurrent\",\"sinistral\",\"dextral\",\"thrust\",\"fold\",\"shear zone\",\"shear\"]\n",
        "    }\n",
        "try: ALIAS_MAP\n",
        "except NameError:\n",
        "    ALIAS_MAP = {\"gold\":\"Au\",\"arsenic\":\"As\",\"antimony\":\"Sb\",\"copper\":\"Cu\",\"lead\":\"Pb\",\"zinc\":\"Zn\",\"sulfur\":\"S\",\"sulphur\":\"S\"}\n",
        "ASSAY_SYMBOLS = set(DICT.get(\"assay_elements\", []))\n",
        "METHOD_TERMS  = set(t.lower() for t in DICT.get(\"methods\", []))\n",
        "GEOCHRON_CUES = {t.lower() for t in DICT.get(\"geochronology_terms\", [])} | {\"u–pb\",\"u-pb\",\"concordia\",\"mswd\",\"age\",\"dated\"}\n",
        "\n",
        "# --- Helpers ---\n",
        "def norm_unit(u):\n",
        "    if not u: return None\n",
        "    s = str(u).strip().lower().replace(\"ug/g\",\"µg/g\").replace(\"deg c\",\"°c\")\n",
        "    return {\"ma\":\"Ma\",\"ga\":\"Ga\",\"°c\":\"°C\",\"percent\":\"%\",\"wt%\":\"%\",\"gpt\":\"g/t\"}.get(s, s)\n",
        "\n",
        "def find_method(low):  # from text.lower()\n",
        "    for m in METHOD_TERMS:\n",
        "        if m in low: return m.upper()\n",
        "    return None\n",
        "\n",
        "def find_element_attribute(text):\n",
        "    # prefer exact symbols (Au, As, …). If none, use ALIAS_MAP words.\n",
        "    tokens = sorted(list(ASSAY_SYMBOLS), key=len, reverse=True)\n",
        "    for sym in tokens:\n",
        "        if re.search(rf\"(?<![A-Za-z0-9]){re.escape(sym)}(?![A-Za-z0-9])\", text, re.I):\n",
        "            return sym\n",
        "    low = text.lower()\n",
        "    for k,v in ALIAS_MAP.items():\n",
        "        if re.search(rf\"\\b{k}\\b\", low): return v\n",
        "    return None\n",
        "\n",
        "def snippet(s, n=240):\n",
        "    t = \" \".join(str(s).split())\n",
        "    return (t[:n]+\"…\") if len(t)>n else t\n",
        "\n",
        "def base_conf(numtype):\n",
        "    return {\"plusminus\":0.90,\"range\":0.80,\"oxide_pct\":0.85,\"num_unit\":0.75}.get(numtype,0.60)\n",
        "\n",
        "# --- Tectonism detection (D1–D4 + tectonic words) ---\n",
        "EVENT_STAGE_RE  = re.compile(r'\\bD\\s*([1-4])\\b', re.I)\n",
        "TECTONIC_TERMS  = {t.lower() for t in DICT.get(\"tectonism_event\", [])} - {\"d1\",\"d2\",\"d3\",\"d4\"}\n",
        "def detect_stage(low):\n",
        "    m = EVENT_STAGE_RE.search(low);  return f\"D{m.group(1)}\" if m else None\n",
        "def has_tectonic(low):\n",
        "    return bool(EVENT_STAGE_RE.search(low) or any(w in low for w in TECTONIC_TERMS))\n",
        "\n",
        "# --- Dictionary tagger (fast boundary-aware) ---\n",
        "def _compile_terms(terms):\n",
        "    terms = sorted(set(terms), key=len, reverse=True)\n",
        "    parts = [r\"\\b\"+re.escape(t).replace(r\"\\ \", r\"\\s+\")+r\"\\b\" for t in terms]\n",
        "    return re.compile(\"|\".join(parts), re.I) if parts else None\n",
        "TAG_CATS = [\"rock_type\",\"minerals\",\"mineralisation\",\"structures\",\"methods\",\"geochronology_terms\"]\n",
        "PAT = {c:_compile_terms(DICT[c]) for c in TAG_CATS}\n",
        "def find_terms(s, cat):\n",
        "    pat = PAT.get(cat);\n",
        "    if not pat: return []\n",
        "    hits = pat.findall(s or \"\")\n",
        "    # normalise to canonical spellings\n",
        "    canon = set(DICT[cat]); out=[]\n",
        "    for h in hits:\n",
        "        if isinstance(h,tuple): h=[x for x in h if x][0]\n",
        "        hc = next((c for c in canon if c.lower()==str(h).lower()), h)\n",
        "        if hc not in out: out.append(hc)\n",
        "    return out\n",
        "\n",
        "# --- Core conversion ---\n",
        "ALLOWED_CATEGORIES = [\"lithology\",\"rock_type\",\"minerals\",\"mineralisation\",\"tectonism_event\",\"structures\",\n",
        "                      \"assay\",\"geochemistry\",\"geochronology\",\"magmatism\",\"methods\",\"stratigraphy\"]\n",
        "\n",
        "rows=[]\n",
        "for _, r in df_cands.iterrows():\n",
        "    text = str(r[\"text\"]); low = text.lower()\n",
        "    page = int(r[\"page_num\"]); block_id = str(r[\"block_id\"])\n",
        "    method = find_method(low)\n",
        "    try:\n",
        "        items = json.loads(r[\"numbers_json\"]) if r.get(\"numbers_json\") else []\n",
        "    except Exception:\n",
        "        items = []\n",
        "\n",
        "    # tags once per block (from full text)\n",
        "    tags = {f\"tags_{c}\":\"; \".join(find_terms(text, c)) for c in TAG_CATS}\n",
        "    dict_tags = \" | \".join(f\"{k[5:]}:{v}\" for k,v in tags.items() if v)\n",
        "\n",
        "    for it in items:\n",
        "        ntype = it.get(\"type\"); conf = base_conf(ntype)\n",
        "        if ntype == \"oxide_pct\":\n",
        "            rows.append({\n",
        "                \"category\":\"geochemistry\",\"entity\":None,\"attribute\":it.get(\"oxide\"),\n",
        "                \"value\":float(it.get(\"value\")) if it.get(\"value\") is not None else None,\n",
        "                \"unit\":\"%\",\"value_min\":None,\"value_max\":None,\"error\":None,\"error_unit\":None,\n",
        "                \"method\":method,\"mineral_phase\":None,\"sample_id\":None,\n",
        "                \"context_snippet\":snippet(text),\"page\":page,\"block_id\":block_id,\n",
        "                \"confidence\":min(1.0, conf + (0.05 if method else 0)), **tags, \"dict_tags\":dict_tags\n",
        "            }); continue\n",
        "\n",
        "        if ntype == \"plusminus\":\n",
        "            unit = norm_unit(it.get(\"unit\")); mean = it.get(\"mean\"); err = it.get(\"error\")\n",
        "            is_age = (unit in (\"Ma\",\"Ga\")) or any(c in low for c in GEOCHRON_CUES)\n",
        "            stage  = detect_stage(low) if is_age and has_tectonic(low) else None\n",
        "            if is_age and stage:   cat, attr, ent = \"tectonism_event\",\"age\",stage\n",
        "            elif is_age:           cat, attr, ent = \"geochronology\",\"age\",None\n",
        "            else:\n",
        "                attr_guess = find_element_attribute(text) or \"value\"\n",
        "                cat, attr, ent = \"assay\", attr_guess, None\n",
        "            rows.append({\n",
        "                \"category\":cat,\"entity\":ent,\"attribute\":attr,\n",
        "                \"value\":float(mean) if mean is not None else None, \"unit\":unit,\n",
        "                \"value_min\":None,\"value_max\":None,\n",
        "                \"error\":float(err) if err is not None else None,\"error_unit\":unit,\n",
        "                \"method\":method,\"mineral_phase\":None,\"sample_id\":None,\n",
        "                \"context_snippet\":snippet(text),\"page\":page,\"block_id\":block_id,\n",
        "                \"confidence\":min(1.0, conf + (0.1 if (is_age or method) else 0)), **tags, \"dict_tags\":dict_tags\n",
        "            }); continue\n",
        "\n",
        "        if ntype == \"range\":\n",
        "            vmin = it.get(\"value_min\"); vmax = it.get(\"value_max\"); unit = norm_unit(it.get(\"unit\"))\n",
        "            is_age = (unit in (\"Ma\",\"Ga\")) or any(c in low for c in GEOCHRON_CUES)\n",
        "            stage  = detect_stage(low) if is_age and has_tectonic(low) else None\n",
        "            if is_age and stage:   cat, attr, ent = \"tectonism_event\",\"age\",stage\n",
        "            elif is_age:           cat, attr, ent = \"geochronology\",\"age\",None\n",
        "            else:\n",
        "                attr_guess = find_element_attribute(text) or \"value\"\n",
        "                cat = \"assay\" if unit in (\"ppm\",\"ppb\",\"g/t\",\"mg/kg\",\"µg/g\",\"%\",\"wt%\") else \"geochemistry\"\n",
        "                attr, ent = attr_guess, None\n",
        "            rows.append({\n",
        "                \"category\":cat,\"entity\":ent,\"attribute\":attr,\n",
        "                \"value\":None,\"unit\":unit,\n",
        "                \"value_min\":float(vmin) if vmin is not None else None,\n",
        "                \"value_max\":float(vmax) if vmax is not None else None,\n",
        "                \"error\":None,\"error_unit\":None,\n",
        "                \"method\":method,\"mineral_phase\":None,\"sample_id\":None,\n",
        "                \"context_snippet\":snippet(text),\"page\":page,\"block_id\":block_id,\n",
        "                \"confidence\":min(1.0, conf + (0.05 if method else 0)), **tags, \"dict_tags\":dict_tags\n",
        "            }); continue\n",
        "\n",
        "        if ntype == \"num_unit\":\n",
        "            val = it.get(\"value\"); unit = norm_unit(it.get(\"unit\"))\n",
        "            is_age = (unit in (\"Ma\",\"Ga\")) or any(c in low for c in GEOCHRON_CUES)\n",
        "            stage  = detect_stage(low) if is_age and has_tectonic(low) else None\n",
        "            if is_age and stage:   cat, attr, ent = \"tectonism_event\",\"age\",stage\n",
        "            elif is_age:           cat, attr, ent = \"geochronology\",\"age\",None\n",
        "            else:\n",
        "                attr_guess = find_element_attribute(text)\n",
        "                if attr_guess:     cat, attr, ent = \"assay\", attr_guess, None\n",
        "                else:              cat, attr, ent = \"geochemistry\",\"value\", None\n",
        "            rows.append({\n",
        "                \"category\":cat,\"entity\":ent,\"attribute\":attr,\n",
        "                \"value\":float(val) if val is not None else None, \"unit\":unit,\n",
        "                \"value_min\":None,\"value_max\":None,\"error\":None,\"error_unit\":None,\n",
        "                \"method\":method,\"mineral_phase\":None,\"sample_id\":None,\n",
        "                \"context_snippet\":snippet(text),\"page\":page,\"block_id\":block_id,\n",
        "                \"confidence\":min(1.0, conf + (0.05 if method else 0)), **tags, \"dict_tags\":dict_tags\n",
        "            }); continue\n",
        "\n",
        "cols = [\"category\",\"entity\",\"attribute\",\"value\",\"unit\",\"value_min\",\"value_max\",\"error\",\"error_unit\",\n",
        "        \"method\",\"mineral_phase\",\"sample_id\",\"context_snippet\",\"page\",\"block_id\",\"confidence\"] + \\\n",
        "       [f\"tags_{c}\" for c in TAG_CATS] + [\"dict_tags\"]\n",
        "df4 = pd.DataFrame(rows, columns=cols).dropna(how=\"all\")\n",
        "# keep allowed categories and numeric-bearing rows\n",
        "df4 = df4[df4[\"category\"].isin(ALLOWED_CATEGORIES)]\n",
        "num_mask = df4[\"value\"].notna() | df4[\"value_min\"].notna() | df4[\"value_max\"].notna() | df4[\"error\"].notna()\n",
        "df4 = df4[num_mask].reset_index(drop=True)\n",
        "\n",
        "# Save\n",
        "with open(OUT_JSONL,\"w\",encoding=\"utf-8\") as f:\n",
        "    for _,row in df4.iterrows(): f.write(json.dumps(row.to_dict(), ensure_ascii=False)+\"\\n\")\n",
        "df4.to_csv(OUT_CSV, index=False)\n",
        "try: df4.to_parquet(OUT_PARQ, index=False)\n",
        "except Exception: pass\n",
        "\n",
        "print(f\"[Step4] Saved → {OUT_CSV} (rows={len(df4)})\")\n",
        "print(df4.head(8).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmZxkzm1eVlW",
        "outputId": "be5b841a-59ed-4a43-c5dc-a5d53bb6196d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step4] Saved → /content/extracted_step4_offline.csv (rows=298)\n",
            "     category entity attribute  value unit  value_min  value_max  error error_unit method mineral_phase sample_id                                                                        context_snippet  page block_id  confidence tags_rock_type tags_minerals tags_mineralisation tags_structures tags_methods tags_geochronology_terms                                      dict_tags\n",
            "geochronology   None       age 2158.0   Ma        NaN        NaN    NaN       None   None          None      None 2158 Ma gold at Wassa, Parra-Avila, in press; 2105 ± 2 Ma gold at Ashanti, Oberthür et    19    19-18        0.75                                                                                                                                                      \n",
            "geochronology   None       age    2.0   Ma        NaN        NaN    NaN       None   None          None      None 2158 Ma gold at Wassa, Parra-Avila, in press; 2105 ± 2 Ma gold at Ashanti, Oberthür et    19    19-18        0.75                                                                                                                                                      \n",
            "geochronology   None       age 2105.0   Ma        NaN        NaN    2.0         Ma   None          None      None 2158 Ma gold at Wassa, Parra-Avila, in press; 2105 ± 2 Ma gold at Ashanti, Oberthür et    19    19-18        1.00                                                                                                                                                      \n",
            "geochronology   None       age    9.0   Ma        NaN        NaN    NaN       None   None          None      None    al., 1998; 2063 ± 9 Ma gold at Damang, Pigois et al., 2003). Nevertheless, the vast    19    19-19        0.75                                                                                                                                                      \n",
            "geochronology   None       age 2063.0   Ma        NaN        NaN    9.0         Ma   None          None      None    al., 1998; 2063 ± 9 Ma gold at Damang, Pigois et al., 2003). Nevertheless, the vast    19    19-19        1.00                                                                                                                                                      \n",
            "geochronology   None       age 2060.0   Ma        NaN        NaN    NaN       None   None          None      None          Eburnean orogeny dated between 2115 and 2060 Ma (e.g., Feybesse et al., 2006;    19    19-23        0.75                                                                                                  dated                      geochronology_terms:dated\n",
            "geochronology   None       age    NaN   Ma     2115.0     2060.0    NaN       None   None          None      None          Eburnean orogeny dated between 2115 and 2060 Ma (e.g., Feybesse et al., 2006;    19    19-23        0.80                                                                                                  dated                      geochronology_terms:dated\n",
            "geochronology   None       age   16.0   Ma        NaN        NaN    NaN       None   None          None      None     dated between 2160 ± 16 Ma (Boher et al., 199 2; Sm-Nd on whole rock andesite) and    42    42-18        0.75       andesite                                                                                   dated rock_type:andesite | geochronology_terms:dated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 — Packaging, lookups & exports (offline)\n",
        "\n",
        "Normalises units/types and prints quick category/page counts.\n",
        "Writes per-category CSVs and lookups: ages (converted to Ma, default ±1 Ma if missing error) and assays.\n",
        "Exports a compact catalog.jsonl for fast search/grepping."
      ],
      "metadata": {
        "id": "5JMLmhXpphue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 5) Packaging, Lookups & Exports (offline) =====\n",
        "import os, json, re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "SRC = \"/content/extracted_step4_offline.csv\"  # from Step 4\n",
        "OUT_DIR = \"/content/step5_offline\"\n",
        "Path(OUT_DIR).mkdir(exist_ok=True)\n",
        "assert Path(SRC).exists(), f\"Missing {SRC}\"\n",
        "df = pd.read_csv(SRC)\n",
        "\n",
        "# type hygiene\n",
        "for c in [\"value\",\"value_min\",\"value_max\",\"error\",\"confidence\",\"page\"]:\n",
        "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "def _u(u):\n",
        "    if pd.isna(u): return None\n",
        "    s=str(u).strip().replace(\"ug/g\",\"µg/g\").lower()\n",
        "    return {\"ma\":\"Ma\",\"ga\":\"Ga\",\"°c\":\"°C\",\"percent\":\"%\",\"wt%\":\"%\",\"gpt\":\"g/t\"}.get(s, s)\n",
        "for c in (\"unit\",\"error_unit\"):\n",
        "    if c in df.columns: df[c]=df[c].apply(_u)\n",
        "\n",
        "# Summary\n",
        "print(\"By category:\\n\", df[\"category\"].value_counts().to_string())\n",
        "\n",
        "# Per-category CSVs\n",
        "CAT_DIR = f\"{OUT_DIR}/by_category\"; Path(CAT_DIR).mkdir(exist_ok=True)\n",
        "for cat, sub in df.groupby(df[\"category\"].fillna(\"uncategorized\")):\n",
        "    cols = [x for x in [\"page\",\"block_id\",\"entity\",\"category\",\"attribute\",\"value\",\"value_min\",\"value_max\",\"unit\",\n",
        "                        \"error\",\"error_unit\",\"method\",\"mineral_phase\",\"sample_id\",\"context_snippet\",\"confidence\",\n",
        "                        \"tags_rock_type\",\"tags_minerals\",\"tags_structures\",\"dict_tags\"]\n",
        "            if x in sub.columns]\n",
        "    sub.sort_values([\"page\",\"block_id\",\"attribute\",\"value\"], inplace=True, na_position=\"last\")\n",
        "    sub[cols].to_csv(f\"{CAT_DIR}/{cat}.csv\", index=False)\n",
        "print(f\"Saved per-category → {CAT_DIR}\")\n",
        "\n",
        "# Lookups\n",
        "# Ages (default ±1 Ma window if no explicit error)\n",
        "ages = df[df[\"category\"].str.lower()==\"geochronology\"].copy()\n",
        "def to_Ma(v,u):\n",
        "    if pd.isna(v): return None\n",
        "    if u==\"Ma\": return float(v)\n",
        "    if u==\"Ga\": return float(v)*1000.0\n",
        "    return None\n",
        "if not ages.empty:\n",
        "    ages[\"age_central_Ma\"] = [to_Ma(v,u) for v,u in zip(ages.get(\"value\"), ages.get(\"unit\"))]\n",
        "    def err_Ma(e, eu):\n",
        "        if pd.isna(e) or pd.isna(eu): return None\n",
        "        return e if eu==\"Ma\" else (e*1000.0 if eu==\"Ga\" else None)\n",
        "    ages[\"age_error_Ma\"]  = [err_Ma(e,eu) for e,eu in zip(ages.get(\"error\"), ages.get(\"error_unit\"))]\n",
        "    ages[\"age_window_Ma\"] = ages[\"age_error_Ma\"].where(ages[\"age_error_Ma\"].notna(), 1.0)\n",
        "    ages[\"age_lo_Ma\"]     = ages[\"age_central_Ma\"] - ages[\"age_window_Ma\"]\n",
        "    ages[\"age_hi_Ma\"]     = ages[\"age_central_Ma\"] + ages[\"age_window_Ma\"]\n",
        "    keep = [c for c in [\"page\",\"block_id\",\"entity\",\"attribute\",\"value\",\"unit\",\"error\",\"error_unit\",\n",
        "                        \"method\",\"mineral_phase\",\"sample_id\",\"age_central_Ma\",\"age_window_Ma\",\"age_lo_Ma\",\"age_hi_Ma\",\n",
        "                        \"context_snippet\",\"confidence\"] if c in ages.columns]\n",
        "    ages.sort_values([\"age_central_Ma\",\"page\",\"confidence\"], inplace=True, ascending=[True,True,False])\n",
        "    ages.to_csv(f\"{OUT_DIR}/lookup_geochronology.csv\", index=False)\n",
        "\n",
        "# Assays\n",
        "assay = df[df[\"category\"].str.lower()==\"assay\"].copy()\n",
        "if not assay.empty:\n",
        "    keep = [c for c in [\"page\",\"block_id\",\"entity\",\"attribute\",\"value\",\"value_min\",\"value_max\",\"unit\",\n",
        "                        \"method\",\"sample_id\",\"context_snippet\",\"confidence\"] if c in assay.columns]\n",
        "    assay.sort_values([\"attribute\",\"page\",\"value\",\"confidence\"], inplace=True, ascending=[True,True,True,False])\n",
        "    assay[keep].to_csv(f\"{OUT_DIR}/lookup_assays.csv\", index=False)\n",
        "\n",
        "# Catalog JSONL\n",
        "CATALOG = f\"{OUT_DIR}/catalog.jsonl\"\n",
        "with open(CATALOG,\"w\",encoding=\"utf-8\") as f:\n",
        "    for _,r in df.iterrows():\n",
        "        f.write(json.dumps({k:r.get(k) for k in\n",
        "               [\"category\",\"attribute\",\"unit\",\"value\",\"value_min\",\"value_max\",\"error\",\"error_unit\",\n",
        "                \"page\",\"block_id\",\"entity\",\"confidence\",\"context_snippet\",\"dict_tags\"]}, ensure_ascii=False)+\"\\n\")\n",
        "print(\"Step 5 done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRiDGmDEPa4s",
        "outputId": "5fa7e4e4-e827-441e-901e-becd88fb4e7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By category:\n",
            " category\n",
            "geochronology      245\n",
            "geochemistry        37\n",
            "assay               14\n",
            "tectonism_event      2\n",
            "Saved per-category → /content/step5_offline/by_category\n",
            "Step 5 done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 — Noise reduction & confidence gating\n",
        "\n",
        "Scores each fact with penalties (e.g., age without Ma/Ga, assay without unit, ref-section text) and bonuses (method present, ±error, dict tags).\n",
        "Computes conf_final and splits rows into clean, review, and dropped sets.\n",
        "Saves facts_step6_clean.csv, facts_step6_review.csv, and facts_step6_dropped.csv."
      ],
      "metadata": {
        "id": "V3amVfbxpm3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 6) Noise Reduction & Confidence Gating =====\n",
        "import pandas as pd, re\n",
        "from pathlib import Path\n",
        "\n",
        "SRC = \"/content/extracted_step4_offline.csv\"  # from Step 4\n",
        "assert Path(SRC).exists(), f\"Missing {SRC}\"\n",
        "df = pd.read_csv(SRC)\n",
        "\n",
        "for c in [\"value\",\"value_min\",\"value_max\",\"error\",\"confidence\",\"page\"]:\n",
        "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# Penalties/bonuses\n",
        "def penalties(row):\n",
        "    p=0.0; snip=str(row.get(\"context_snippet\") or \"\")\n",
        "    cat=str(row.get(\"category\") or \"\")\n",
        "    unit=str(row.get(\"unit\") or \"\")\n",
        "    # hard noise words\n",
        "    if re.search(r'\\b(references|bibliograph|acknowledg|appendix)\\b', snip, re.I): p+=0.25\n",
        "    # ages must have Ma/Ga\n",
        "    if cat==\"geochronology\" and unit not in (\"Ma\",\"Ga\"): p+=0.35\n",
        "    # assays/geochem should have units\n",
        "    if cat in (\"assay\",\"geochemistry\") and unit in (\"\",None): p+=0.25\n",
        "    # very short context = risk\n",
        "    if len(snip)<30: p+=0.05\n",
        "    # suspicious % without oxide/chem words\n",
        "    if unit==\"%\" and not re.search(r'(SiO2|Al2O3|FeO|MgO|CaO|Na2O|K2O|TiO2|oxide|wt%)', snip, re.I):\n",
        "        p+=0.15\n",
        "    return p\n",
        "\n",
        "def bonuses(row):\n",
        "    b=0.0; snip=str(row.get(\"context_snippet\") or \"\")\n",
        "    # dictionary tags present → more trust\n",
        "    if str(row.get(\"dict_tags\") or \"\")!=\"\": b+=0.05\n",
        "    # method named\n",
        "    if str(row.get(\"method\") or \"\")!=\"\": b+=0.05\n",
        "    # explicit ± uncertainty\n",
        "    if pd.notna(row.get(\"error\")): b+=0.08\n",
        "    return b\n",
        "\n",
        "base = df.get(\"confidence\", pd.Series([0.6]*len(df)))\n",
        "df[\"penalty\"]   = df.apply(penalties, axis=1)\n",
        "df[\"bonus\"]     = df.apply(bonuses, axis=1)\n",
        "df[\"conf_final\"]= (base - df[\"penalty\"] + df[\"bonus\"]).clip(0.0,1.0)\n",
        "\n",
        "# Gate\n",
        "KEEP_THR   = 0.66\n",
        "REVIEW_THR = 0.40\n",
        "keep_mask  = df[\"conf_final\"] >= KEEP_THR\n",
        "review_mask= (df[\"conf_final\"] >= REVIEW_THR) & (~keep_mask)\n",
        "\n",
        "df_clean  = df[keep_mask].copy()\n",
        "df_review = df[review_mask].copy()\n",
        "df_drop   = df[~(keep_mask | review_mask)].copy()\n",
        "\n",
        "df_clean.to_csv(\"/content/facts_step6_clean.csv\",  index=False)\n",
        "df_review.to_csv(\"/content/facts_step6_review.csv\", index=False)\n",
        "df_drop.to_csv(\"/content/facts_step6_dropped.csv\", index=False)\n",
        "\n",
        "print(f\"[Step6] kept={len(df_clean)}  review={len(df_review)}  dropped={len(df_drop)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvF9FDSpgjoJ",
        "outputId": "69c73b60-2242-4c0f-86cb-2d850fe0d7df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step6] kept=273  review=25  dropped=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 — Provenance & references (offline)\n",
        "\n",
        "Reads page text and adds section_title, nearby author–year citations, and figure/table IDs.\n",
        "Builds stable provenance_id as PDF_NAME#p{page}:{block_id} plus a viewer #page= hint.\n",
        "Writes the enriched table to /content/facts_step8_provenance_offline.csv."
      ],
      "metadata": {
        "id": "MI3EuOmZpqp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 7 (OFFLINE): Referencing & Provenance Attachment =====\n",
        "# Works with outputs from Step 4 (offline) OR Step 6.\n",
        "# Produces /content/facts_step8_provenance_offline.csv\n",
        "\n",
        "!pip -q install pypdf pandas\n",
        "\n",
        "import os, re, json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from pypdf import PdfReader\n",
        "\n",
        "# ---------- Inputs ----------\n",
        "PDF_PATH = globals().get(\"PDF_PATH\", \"/content/PhDThesis__Masurel2015.pdf\")\n",
        "FACTS_CANDIDATES = [\n",
        "    \"/content/facts_step7_postproc.csv\",        # if you ran Step 7\n",
        "    \"/content/facts_step6_clean.csv\",           # Step 6 clean\n",
        "    \"/content/facts_postproc_master.csv\",       # alt name\n",
        "    \"/content/extracted_step4_offline.csv\",     # Step 4 (offline)\n",
        "    \"/content/extracted_step4_offline.jsonl\",\n",
        "    \"/content/extracted_step4_offline.parquet\",\n",
        "]\n",
        "assert Path(PDF_PATH).exists(), f\"Missing PDF at: {PDF_PATH}\"\n",
        "PDF_NAME = Path(PDF_PATH).name\n",
        "\n",
        "def load_facts(paths=FACTS_CANDIDATES) -> pd.DataFrame:\n",
        "    for p in paths:\n",
        "        pth = Path(p)\n",
        "        if not pth.exists():\n",
        "            continue\n",
        "        if pth.suffix == \".csv\":\n",
        "            df = pd.read_csv(pth)\n",
        "        elif pth.suffix == \".jsonl\":\n",
        "            df = pd.read_json(pth, lines=True)\n",
        "        else:\n",
        "            try:\n",
        "                df = pd.read_parquet(pth)\n",
        "            except Exception:\n",
        "                continue\n",
        "        if not df.empty:\n",
        "            print(f\"[Step8] Loaded facts: {p} (rows={len(df)})\")\n",
        "            return df\n",
        "    raise FileNotFoundError(\"No Step-7/6/4 artifacts found. Run Step 4 (offline) or Step 6 first.\")\n",
        "\n",
        "df = load_facts()\n",
        "\n",
        "# ---------- Minimal hygiene ----------\n",
        "for c in (\"page\",\"confidence\"):\n",
        "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "for c in (\"context_snippet\",\"block_id\",\"pdf_name\",\"provenance_id\",\"figure_table_id\"):\n",
        "    if c not in df.columns: df[c] = \"\"\n",
        "\n",
        "# ---------- Read PDF text (per page) ----------\n",
        "def read_pdf_pages_text(pdf_path: str):\n",
        "    rdr = PdfReader(pdf_path)\n",
        "    out = []\n",
        "    for pg in rdr.pages:\n",
        "        try:\n",
        "            t = pg.extract_text() or \"\"\n",
        "        except Exception:\n",
        "            t = \"\"\n",
        "        # common encoding fixes so regex works\n",
        "        t = (t.replace(\"Â±\", \"±\")\n",
        "               .replace(\"\\u2013\", \"-\")   # en dash -> hyphen\n",
        "               .replace(\"\\u2014\", \"-\"))  # em dash -> hyphen\n",
        "        out.append(t)\n",
        "    return out\n",
        "\n",
        "pages_text = read_pdf_pages_text(PDF_PATH)\n",
        "N = len(pages_text)\n",
        "\n",
        "# ---------- Heuristics ----------\n",
        "TITLE_PATS = [\n",
        "    r'^\\s*(chapter\\s+[ivxlcdm\\d]+\\.?\\s+.*)$',  # \"Chapter I ...\", \"Chapter 1 ...\"\n",
        "    r'^\\s*chapter\\s+.*$',                      # loose chapter line\n",
        "    r'^\\s*\\d+\\.\\s+[A-Z].{3,}$',                # \"1. Title\"\n",
        "    r'^\\s*[A-Z][A-Za-z0-9\\s\\-\\(\\),:]{4,}$',    # Title-like single line\n",
        "]\n",
        "TITLE_RE = re.compile(\"|\".join(TITLE_PATS), re.IGNORECASE | re.MULTILINE)\n",
        "\n",
        "def guess_section_title(pg_text: str) -> str|None:\n",
        "    lines = (pg_text or \"\").strip().splitlines()\n",
        "    for line in lines[:25]:\n",
        "        m = TITLE_RE.search(line.strip())\n",
        "        if m:\n",
        "            return (m.group(m.lastindex) if m.lastindex else line).strip()\n",
        "    return None\n",
        "\n",
        "FIGTAB_RE = re.compile(r'\\b((?:Figure|Fig\\.|Table)\\s+\\d+[A-Za-z]?)\\b', re.I)\n",
        "def extract_figtab(text: str, limit=6):\n",
        "    found = [m.group(1).strip() for m in FIGTAB_RE.finditer(text or \"\")]\n",
        "    # de-dup preserve order\n",
        "    seen, out = set(), []\n",
        "    for x in found:\n",
        "        if x not in seen:\n",
        "            out.append(x); seen.add(x)\n",
        "    return out[:limit]\n",
        "\n",
        "CITE_RE = re.compile(\n",
        "    r'\\(([A-Z][A-Za-z\\-]+(?:\\s*&\\s*[A-Z][A-Za-z\\-]+)?|[A-Z][A-Za-z\\-]+ et al\\.)\\s*,\\s*(\\d{4}[a-z]?)\\)',\n",
        "    re.UNICODE\n",
        ")\n",
        "def extract_citations(text: str, limit=8):\n",
        "    t = (text or \"\").replace(\"Â±\",\"±\")\n",
        "    hits = [f\"{a} {y}\" for a, y in CITE_RE.findall(t)]\n",
        "    seen, out = set(), []\n",
        "    for h in hits:\n",
        "        if h not in seen:\n",
        "            out.append(h); seen.add(h)\n",
        "    return out[:limit]\n",
        "\n",
        "# ---------- Enrich each fact ----------\n",
        "enriched = []\n",
        "for _, r in df.iterrows():\n",
        "    page = int(r.get(\"page\")) if pd.notna(r.get(\"page\")) else 1\n",
        "    page = 1 if page < 1 else page\n",
        "    pg_idx = min(max(0, page-1), N-1)\n",
        "    pg_text = pages_text[pg_idx] if 0 <= pg_idx < N else \"\"\n",
        "\n",
        "    section_title = guess_section_title(pg_text) or \"\"\n",
        "\n",
        "    ctx = str(r.get(\"context_snippet\") or \"\")\n",
        "    cites = list(dict.fromkeys(extract_citations(ctx) + extract_citations(pg_text)))\n",
        "    figtab = []\n",
        "    if str(r.get(\"figure_table_id\") or \"\").strip():\n",
        "        figtab.append(str(r.get(\"figure_table_id\")).strip())\n",
        "    figtab += extract_figtab(ctx)\n",
        "    if not figtab:\n",
        "        figtab += extract_figtab(pg_text)\n",
        "    figtab = list(dict.fromkeys(figtab))[:6]\n",
        "    figure_table_id = \"; \".join(figtab)\n",
        "\n",
        "    prov_existing = str(r.get(\"provenance_id\") or \"\").strip()\n",
        "    block_id = str(r.get(\"block_id\") or \"\").strip()\n",
        "    provenance_id = prov_existing if prov_existing else f\"{PDF_NAME}#p{page}:{block_id}\"\n",
        "    pdf_page_hint = f\"#page={page}\"\n",
        "    provenance_note = f\"{PDF_NAME} page {page}, block {block_id}\"\n",
        "\n",
        "    row = dict(r)\n",
        "    row.update({\n",
        "        \"pdf_name\": row.get(\"pdf_name\") or PDF_NAME,\n",
        "        \"section_title\": section_title,\n",
        "        \"local_citations\": \"; \".join(cites) if cites else \"\",\n",
        "        \"figure_table_id\": figure_table_id,\n",
        "        \"provenance_id\": provenance_id,\n",
        "        \"pdf_page_hint\": pdf_page_hint,\n",
        "        \"provenance_note\": provenance_note,\n",
        "    })\n",
        "    enriched.append(row)\n",
        "\n",
        "df8 = pd.DataFrame(enriched)\n",
        "\n",
        "# ---------- Save ----------\n",
        "OUT = \"/content/facts_step8_provenance_offline.csv\"\n",
        "df8.to_csv(OUT, index=False)\n",
        "print(f\"[Step8] Saved with provenance → {OUT}\")\n",
        "\n",
        "# ---------- Peek ----------\n",
        "cols = [c for c in [\n",
        "    \"category\",\"attribute\",\"value\",\"value_min\",\"value_max\",\"unit\",\"error\",\n",
        "    \"page\",\"block_id\",\"section_title\",\"figure_table_id\",\"local_citations\",\n",
        "    \"provenance_id\",\"pdf_page_hint\"\n",
        "] if c in df8.columns]\n",
        "print(df8[cols].head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc6LfHhgR8IR",
        "outputId": "cdb579cb-fe69-4682-9f38-43909dcadad8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step8] Loaded facts: /content/facts_step7_postproc.csv (rows=113)\n",
            "[Step8] Saved with provenance → /content/facts_step8_provenance_offline.csv\n",
            "category attribute   value  value_min  value_max unit  error  page block_id                                                                                       section_title                        figure_table_id     local_citations                          provenance_id pdf_page_hint\n",
            "   assay        As  350.00        NaN        NaN   °C    NaN    67     67-7                          Stage II is characterized by the abunda nce of antimony sulfosalts and the Fig. 11C; Fig. 11D; Fig. 11E; Fig. 11F                        PhDThesis__Masurel2015.pdf#p67:67-7      #page=67\n",
            "   assay        Au     NaN      1.000        2.0  g/t    NaN   162   162-28 C) Field photograph showing an ENE-trending steep quartz vein (V 2) cut and sinistrally offset by a                      Figure 4; Fig. 5A                     PhDThesis__Masurel2015.pdf#p162:162-28     #page=162\n",
            "   assay        Au    2.00        NaN        NaN  g/t    NaN   162   162-28 C) Field photograph showing an ENE-trending steep quartz vein (V 2) cut and sinistrally offset by a                      Figure 4; Fig. 5A                     PhDThesis__Masurel2015.pdf#p162:162-28     #page=162\n",
            "   assay        Au    2.86        NaN        NaN  g/t    NaN    44    44-14                                                                                4. Mining background                                        Boshoff et al. 1998   PhDThesis__Masurel2015.pdf#p44:44-14      #page=44\n",
            "   assay        Au    0.15        NaN        NaN  ppm    NaN    66    66-33                   Ore minerals are texturally associated with silicate minerals precipitated during          Figure 10; Fig. 11A; Fig. 11B                       PhDThesis__Masurel2015.pdf#p66:66-33      #page=66\n",
            "   assay        Au    3.02        NaN        NaN  ppm    NaN    66    66-32                   Ore minerals are texturally associated with silicate minerals precipitated during          Figure 10; Fig. 11A; Fig. 11B                       PhDThesis__Masurel2015.pdf#p66:66-32      #page=66\n",
            "   assay        Au     NaN      0.126       23.7  ppm    NaN    66    66-32                   Ore minerals are texturally associated with silicate minerals precipitated during          Figure 10; Fig. 11A; Fig. 11B                       PhDThesis__Masurel2015.pdf#p66:66-32      #page=66\n",
            "   assay        Au   23.70        NaN        NaN  ppm    NaN    66    66-32                   Ore minerals are texturally associated with silicate minerals precipitated during          Figure 10; Fig. 11A; Fig. 11B                       PhDThesis__Masurel2015.pdf#p66:66-32      #page=66\n",
            "   assay        Sb 1368.00        NaN        NaN  ppm    NaN    74    74-37         movement along both the Sadiola Fracture Zone and the NNE-trending shears, synchronous with                              Figure 12  Thorne et al. 2008   PhDThesis__Masurel2015.pdf#p74:74-37      #page=74\n",
            "   assay        Sb  300.00        NaN        NaN   °C    NaN    77    77-13                    The Sadiola Hill deposit shares a number  of characteristics typical of orogenic                                Table 1                       PhDThesis__Masurel2015.pdf#p77:77-13      #page=77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClG8TrmKXb3L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}